# 问题集合 （朋友问的，这里备份一下，自己也好查，所有均自己的理解和总结，如果发现有误请在issus里为我提出。万分感谢）

### 问题： 就像识别手写数字这个程序，如果按你说的一般99%的时间都在调参。可具体到怎么调参有什么思路和技巧吗
> 调参突破口

##### 优先考虑：
* 卷积核 ： 大小、核数、步长 ， 如果图像是奇数边长（基本没人会做这样的数据集）的时候还可以考虑一下Padding
* 池化：ksize 和 步长 ， 池化类型
* 卷积和池化的层数
* 全连接：层数、宽度
* dropout率
* 加bn操作
* LRN操作
* 初始化方式和stddev

##### 次要考虑（一般用到细节优化）:

* Learning_rate

* 交叉熵那儿是求均值还是求和

* 考虑是否提前中断

* 考虑是否需要在训练过程中更改Learning_rate

##### 最次要（一般不好实现）

* 增大数据集，花更多的人力去做出更多数据集

* 采用留一法等其它数据使用方式

### 问题：梯度消融是因为在全连接层选的不是softmax算法造成的？

> 梯度弥散现象的造型

##### 原因：

* sigmoid函数的局限性

* 全连接最后一层用sigmoid，然后使用二次均值loss计算方式

* 层数过高，没有使用relu

##### 解决方式：

* 使用relu

* cross_entropy

* 使用softmax

# tensorflow学习第二天

## MNIST数据集处理

* 首先将数据集（图片）映射成60000*784的张量，60000代表样本的数量，784代表每个样本的属性
* 然后把标签写成只有第n维度的数字为1的10维向量，既labels为一个60000*10的矩阵

### SoftMax回归介绍

* #### 一般分为两步

```txt
第一步，为了得到一张给定图片属于某个特定数字类的证据（evidence），我们对图片像素值进行加权求和。
如果这个像素具有很强的证据说明这张图片不属于该类，那么相应的权值为负数，
相反如果这个像素拥有有利的证据支持这张图片属于这个类，那么权值是正数。
进一步将一个图片的判别问题转换为一个线性问题

这一步主要涉及到对权重值W和偏量b的“优化”
```
```txt
第二步是使用SoftMax来处理线性公式后得到的数据，将数据转换为[0,1]之间的数据，更加便于分析
```
* #### 浅谈SoftMax函数

* 相当于就是目标的取值取exp的值比上每个值取exp的和的比例（相当于概率）
* 问题来了，为啥要取exp函数呢？

```txt
可以将负无穷到0的数值无限逼近于0
```
* 为什么要用SoftMax函数？

```txt
这里的softmax可以看成是一个激励（activation）函数或者链接（link）函数，把我们定义的线性函数的输出转换成我们想要
的格式，也就是关于10个数字类的概率分布。因此，给定一张图片，它对于每一个数字的吻合度可以被softmax函数转换成为一个
概率值。
```
